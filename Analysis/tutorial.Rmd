---
title: "myfirstpackage Tutorial"
author: "Mark Lamin"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Project 3: PACKAGE_NAME Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(myfirstpackage)
library(readr)
```
## Introduction
`myfirstpackage` is a demonstration of statistical concepts learned in the STAT 302 course in Spring 2021. This package contains various functions involving statistical inference and statistical prediction. You can install the package with the following:
```{r eval=FALSE}
devtools::install_github("https://github.com/MarkLamin/myfirstpackage")
```
```{r}
library(myfirstpackage)
```

```{r}
read.csv("../Data/my_gapminder.csv")
read.csv("../Data/my_penguins.csv")
source("../Code/my_rf_cv.R")
```

## Tutorial for Random Forest
```{r, fig.width = 9}
the_data <- matrix(NA, nrow = 90, ncol = 2)

for(i in(1:90)){
  if(1<=i&i<=30){
    the_data[i,1] = my_rf_cv(2)
    the_data[i,2] = "02"
  }else if(31<=i&i<=60){
    the_data[i,1] = my_rf_cv(5)
    the_data[i,2] = "05"
  }else if(61<=i&i<=90){
    the_data[i,1] = my_rf_cv(10)
    the_data[i,2] = "10"
  }
}
the_data <- data.frame(the_data)
           
the_boxplots <- ggplot2::ggplot(data = the_data, mapping = ggplot2::aes(x = X2,
                                               y = as.numeric(X1))) +
  ggplot2::geom_boxplot(color = "blue") + ggplot2::theme_bw() + 
  ggplot2::labs(title = "Random Forest Error Based on Different Fold Values",
                x = "Number of Folds", y = "Cross Validation Error")
the_boxplots

kis2 <- the_data %>% dplyr::filter(the_data$X2 == "02")
kis5 <- the_data %>% dplyr::filter(the_data$X2 == "05")
kis10 <- the_data %>% dplyr::filter(the_data$X2 == "10")

mean_column <- c(mean(as.numeric(as.vector(kis2$X1))),
                 mean(as.numeric(as.vector(kis5$X1))),
                 mean(as.numeric(as.vector(kis10$X1))))
sd_column <- c(sd(as.vector(kis2$X1)), sd(as.vector(kis5$X1)),
               sd(as.vector(kis10$X1)))

a_table <- cbind(mean_column, sd_column)
colnames(a_table) <- c("mean", "sd")
rownames(a_table) <- c("k=2", "k=5", "k=10")
my_tab <- data.frame(a_table)
my_tab
```

We see from the table that the mean and standard deviation of the error decrease as we increase the number of folds. That means that my_rf_cv becomes more accurate and more precise as we increase the number of folds. This makes sense as a greater number of folds allows for more specific predictions and fewer data points causing 

```{r}
ggplot2::ggsave("../Output/Figures/myplot.pdf", the_boxplots)
saveRDS(my_tab, "../Output/Results/mytable.rds")

my_result <- cbind(as.numeric(as.vector(kis2$X1)), as.numeric(as.vector(kis5$X1)),
      as.numeric(as.vector(kis10$X1)))
colnames(my_result) <- c("k=2", "k=5", "k=10")
readr::write_csv(data.frame(my_result), "../Output/Results/myresult.csv")
```
